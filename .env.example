# LLM import use litellm lib (https://docs.litellm.ai/docs/)
LLM_SOURCE='OPENAI'

LLM_TEMPERATURE='0.1'

LLM_RESPONSE_LANGUAGE='English'

# open ai
OPENAI_API_KEY='xx'
OPENAI_API_BASE='https://api.openai.com/v1'
OPENAI_EMBEDDING_MODEL='text-embedding-ada-002'
OPENAI_LLM_MODEL_NORMAL='gpt-3.5-turbo'
OPENAI_LLM_MODEL_SMART='gpt-4-1106-preview'
OPENAI_LLM_MODEL_SMART_LIMIT='128000'
OPENAI_LLM_MODEL_LONG='gpt-3.5-turbo-16k'
OPENAI_LLM_MODEL_VISION='gpt-4-vision-preview'
OPENAI_LLM_MODEL_VISION_LIMIT='128000'

# https://replicate.com to get token
REPLICATE_API_TOKEN='xxx'

## user data directory, store user's applications、functions、application_datas and server datas
DATA_DIR='/workspace/data/'

# cache llm inference and embedding, useful when develop and debug
LLM_CACHE='no'
EMBEDDING_CACHE='yes'
# CACHE_PATH='./llm_cache.json'

# google search tool at https://google.serper.dev
SERPER_API_KEY='xxx'

# Whether to automatically run python, shell, applescript and other codes
# Default no: n
AUTO_RUN='y'

# Logging level
# Default: INFO, can be DEBUG, INFO, WARNING, ERROR
LOG_LEVEL='INFO'

## ui builder directory, webui server(webui/server/server/app.py) will automatically set TSX_BUILDER_DIR to webui/server/server/ts_builder
# TSX_BUILDER_DIR

## local applications code directory. webui server(webui/server/server/app.py) will automatically set LOCAL_APPLICATIONS_DIR to webui/server/server/applicatoins
# LOCAL_APPLICATIONS_DIR

# export $(grep -v '^#' .env | sed 's/^export //g' | xargs)