# LLM import use litellm lib (https://docs.litellm.ai/docs/)
# OPENAI | AZURE | OR other LLM PREFIX
LLM_SOURCE='OPENAI'

LLM_TEMPERATURE='0.1'

# open ai
OPENAI_API_KEY='xx'
OPENAI_API_BASE='https://api.openai.com/v1'
OPENAI_EMBEDDING_MODEL='text-embedding-ada-002'
OPENAI_LLM_MODEL_NORMAL='gpt-3.5-turbo'
OPENAI_LLM_MODEL_SMART='gpt-4'
OPENAI_LLM_MODEL_SMART_LIMIT='8000'
OPENAI_LLM_MODEL_LONG='gpt-4'

# azure open ai
AZURE_API_KEY='xx'
AZURE_API_BASE='xx'
AZURE_API_VERSION='2023-06-01-preview'
AZURE_EMBEDDING_MODEL='azure/ada002'
AZURE_LLM_MODEL_NORMAL='azure/gpt35t'
AZURE_LLM_MODEL_SMART='azure/gpt4'
OPENAI_LLM_MODEL_SMART_LIMIT='8000'
AZURE_LLM_MODEL_LONG='azure/gpt4'

# replicate
REPLICATE_API_TOKEN='xxx'

## user data directory, store user's applications、functions、application_datas and server datas
DATA_DIR='/workspace/data/'

# cache llm inference and embedding, useful when develop and debug
LLM_CACHE='no'
EMBEDDING_CACHE='yes'
# CACHE_PATH='./llm_cache.json'

# google search tool at https://google.serper.dev
SERPER_API_KEY='xxx'

# Whether to automatically run python, shell, applescript and other codes
# Default no: n
AUTO_RUN='y'

# Logging level
# Default: INFO, can be DEBUG, INFO, WARNING, ERROR
LOG_LEVEL='INFO'

## ui builder directory, webui server(webui/server/server/app.py) will automatically set TSX_BUILDER_DIR to webui/server/server/ts_builder
# TSX_BUILDER_DIR

## local applications code directory. webui server(webui/server/server/app.py) will automatically set LOCAL_APPLICATIONS_DIR to webui/server/server/applicatoins
# LOCAL_APPLICATIONS_DIR

# export $(grep -v '^#' .env | sed 's/^export //g' | xargs)